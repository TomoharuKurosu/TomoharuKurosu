{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2Y8lgEQi7UWI2tHsw0CwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomoharuKurosu/TomoharuKurosu/blob/main/%E8%84%B3%E6%B3%A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "VzP1imyvFz1a",
        "outputId": "29981516-9dc9-4214-cf02-3a7a7b68986d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6166a32e23c0>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEEGNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import signal  # butterworth\n",
        "from sklearn.decomposition import FastICA  # ICA\n",
        "from sklearn import preprocessing  # scaling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from models import EEGNet, Conformer\n",
        "\n",
        "\n",
        "def load_eeg(subject: str) -> pd.DataFrame:\n",
        "    \"\"\"Load EEG raw data from certain path\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    subject : string\n",
        "        Name of subject for specifying the path\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    eeg : pandas.DataFrame\n",
        "        EEG raw data\n",
        "    \"\"\"\n",
        "    eeg = pd.read_csv(\n",
        "        f\"./rec_data/{subject}_rec.csv\",\n",
        "        names=[\"unnamed\", \"idx\", \"left\", \"right\", \"cmd\"],\n",
        "        header=0,\n",
        "    )\n",
        "    eeg = eeg.drop([\"unnamed\", \"idx\"], axis=1)\n",
        "    eeg[\"diff\"] = eeg[\"left\"] - eeg[\"right\"]\n",
        "    eeg = eeg.reindex(columns=[\"left\", \"right\", \"diff\", \"cmd\"])\n",
        "    return eeg\n",
        "\n",
        "\n",
        "def plot_eeg(eeg: pd.DataFrame, col_names: list):\n",
        "    \"\"\"Plot EEG data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    eeg : pandas.DataFrame\n",
        "        EEG raw data\n",
        "    col_names : list\n",
        "        List of column names in order to plot certain column\n",
        "    \"\"\"\n",
        "    plt.plot(eeg[col_names], label=col_names)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def preprocess(\n",
        "    eeg: pd.DataFrame, col_names: list, sample_freq: int = 1800, rec_sec: int = 4\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Returns preprocessed EEG data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    eeg : pandas.DataFrame\n",
        "        EEG raw data\n",
        "    col_names : list\n",
        "        List of column names in order to plot certain column\n",
        "    sample_freq : int\n",
        "        Frequency of sample EEG data\n",
        "    rec_sec : int\n",
        "        Recording seconds\n",
        "    Returns\n",
        "    -------\n",
        "    eeg : pandas.DataFrame\n",
        "        Preprocessed EEG data\n",
        "    \"\"\"\n",
        "\n",
        "    # Butterworth filter\n",
        "    sos = signal.butter(\n",
        "        4, [4, 40], btype=\"bandpass\", analog=False, output=\"sos\", fs=sample_freq\n",
        "    )\n",
        "    for col in [\"left\", \"right\", \"diff\"]:\n",
        "        col_dat = eeg.loc[:, [col]].to_numpy().reshape(-1)\n",
        "        col_dat = signal.sosfiltfilt(sos, col_dat)\n",
        "        eeg.loc[:, [col]] = col_dat\n",
        "\n",
        "    # ICA\n",
        "    ICA = FastICA(n_components=3, whiten=\"arbitrary-variance\", random_state=0)\n",
        "    X = eeg.loc[:, [\"left\", \"right\", \"diff\"]].to_numpy()\n",
        "    X_trans = ICA.fit_transform(X)\n",
        "    A_ = ICA.mixing_.T\n",
        "    tmp = np.dot(X_trans, A_)\n",
        "    for idx, col in enumerate([\"left\", \"right\", \"diff\"]):\n",
        "        eeg.loc[:, [col]] = tmp[:, idx]\n",
        "\n",
        "    # remove data across 3 sigma\n",
        "    for col in col_names:\n",
        "        time_series_data = eeg[col].copy()\n",
        "        moving_average = time_series_data.rolling(window=sample_freq * rec_sec).mean()\n",
        "        moving_std = time_series_data.rolling(window=sample_freq * rec_sec).std()\n",
        "        outliers = np.abs(time_series_data - moving_average) > 3 * moving_std\n",
        "\n",
        "        filtered_data = time_series_data\n",
        "        for i in range(1, len(time_series_data)):\n",
        "            if outliers[i]:\n",
        "                filtered_data[i] = filtered_data[i - 1]\n",
        "\n",
        "        eeg[col] = filtered_data\n",
        "\n",
        "    # 0~1 Scaling\n",
        "    mm = preprocessing.MinMaxScaler()\n",
        "    eeg.loc[:, [\"left\", \"right\", \"diff\"]] = mm.fit_transform(\n",
        "        eeg.loc[:, [\"left\", \"right\", \"diff\"]]\n",
        "    )\n",
        "    return eeg\n",
        "\n",
        "\n",
        "def split_data(\n",
        "    eeg: pd.DataFrame, infer_sec: int = 4, rec_sec: int = 8\n",
        ") -> tuple[np.ndarray, np.ndarray, int]:\n",
        "    \"\"\"Generates train/test dataset\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    eeg : pandas.DataFrame\n",
        "        EEG data\n",
        "    infer_sec : int, optional\n",
        "        Seconds for inferring, by default 4\n",
        "    rec_sec : int, optional\n",
        "        Seconds each for each label, by default 8\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df_train : numpy.ndarray\n",
        "        EEG dataframe for training\n",
        "    df_test : numpy.ndarray\n",
        "        EEG dataframe for inferring\n",
        "    infer_len : int\n",
        "        Length of splitted EEG data\n",
        "    \"\"\"\n",
        "    # splitting eeg-data by labels\n",
        "    dataset = []\n",
        "    split_idxs = [0]\n",
        "    for i in range(1, len(eeg)):\n",
        "        if eeg.iloc[i, 3] != eeg.iloc[i - 1, 3]:\n",
        "            split_idxs.append(i)\n",
        "    split_idxs.append(len(eeg))\n",
        "    for i in range(len(split_idxs) - 1):\n",
        "        tmp_data = eeg.iloc[split_idxs[i] : split_idxs[i + 1], :]\n",
        "        dataset.append(tmp_data)\n",
        "\n",
        "    # adjusting each data size to the minimum data size\n",
        "    split_num = rec_sec // infer_sec\n",
        "    infer_len = int(min([len(data) for data in dataset])) // split_num\n",
        "    print(f\"EEG length : {infer_len} frames\")\n",
        "    tmp_dataset = np.empty((1, infer_len, 4))\n",
        "    for data in dataset:\n",
        "        for idx in range(split_num):\n",
        "            tmp_data = data.iloc[infer_len * idx : infer_len * (idx + 1)].to_numpy()\n",
        "            tmp_data = np.expand_dims(tmp_data, 0)\n",
        "            tmp_dataset = np.vstack((tmp_dataset, tmp_data))\n",
        "    dataset = tmp_dataset[1:].astype(\"float32\")\n",
        "\n",
        "    # train,test split\n",
        "    df_train, df_test = train_test_split(\n",
        "        dataset, test_size=0.25, stratify=dataset[:, 0, 3]\n",
        "    )\n",
        "\n",
        "    return df_train, df_test, infer_len\n",
        "\n",
        "\n",
        "class EEGDataset(Dataset):\n",
        "    \"\"\"Dataset of EEG for pytorch\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    dataset : numpy.ndarray\n",
        "        Splitted EEG data\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __getitem__(idx)\n",
        "        Returns data specified by idx.\n",
        "    __len__()\n",
        "        Returns length of dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.dataset[idx, 0, -1]\n",
        "        eeg = torch.tensor(self.dataset[idx, :, :-1])\n",
        "        ret = {\"eeg\": eeg, \"label\": label}\n",
        "        return ret\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def trans_label(y: torch.Tensor, label_num: int = 3) -> torch.Tensor:\n",
        "    \"\"\"Transforms vector into one-hot matrix\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y : torch.Tensor\n",
        "        Label vector\n",
        "    label_num : int\n",
        "        Label number\n",
        "    Returns\n",
        "    -------\n",
        "    label : torch.Tensor\n",
        "        One-hot label, by default 3\n",
        "    \"\"\"\n",
        "    label = torch.tensor(np.zeros((len(y), label_num)))\n",
        "    for i in range(len(y)):\n",
        "        label[i, int(y[i].item())] = 1\n",
        "    return label\n",
        "\n",
        "\n",
        "def train(\n",
        "    dataloader: DataLoader,\n",
        "    model: nn.Module,\n",
        "    loss_fn: nn.modules.loss,\n",
        "    optimizer: optim,\n",
        "    device: torch.device,\n",
        "    state: str = \"Train\",\n",
        ") -> tuple[float, list, list]:\n",
        "    \"\"\"Trains the model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataloader : torch.utils.data.dataloader.DataLoader\n",
        "        EEG dataloader\n",
        "    model : torch.nn.Module\n",
        "        EEG model\n",
        "    loss_fn : torch.nn.modules.loss\n",
        "        Loss function\n",
        "    optimizer : torch.optim\n",
        "        Optimizer fuction\n",
        "    device : torch.device\n",
        "        Current device mode\n",
        "    state : str, optional\n",
        "        State either \"Train\" or \"Val\", by default \"Train\"\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    loss_sum : float\n",
        "        Loss occured in latest train/infer\n",
        "    pred_list : list\n",
        "        List of predicted labels\n",
        "    label_list : list\n",
        "        List of true labels\n",
        "    \"\"\"\n",
        "    loss_sum, correct = 0, 0\n",
        "    pred_list, label_list = [], []\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    if state == \"Train\":\n",
        "        model.train()\n",
        "    elif state == \"Val\":\n",
        "        model.eval()\n",
        "\n",
        "    with torch.set_grad_enabled(state == \"Train\"):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            X = data[\"eeg\"].to(device).unsqueeze(1).permute(0, 1, 3, 2)\n",
        "            y = data[\"label\"].to(device)\n",
        "            y_one_hot = trans_label(y)\n",
        "\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y_one_hot)\n",
        "            loss_sum += loss.item()\n",
        "            correct += (\n",
        "                (torch.argmax(pred, dim=1) == torch.argmax(y_one_hot, dim=1))\n",
        "                .type(torch.float)\n",
        "                .sum()\n",
        "                .item()\n",
        "            )\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            if state == \"Train\":\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(pred, dim=1)\n",
        "            pred_list += [data.item() for data in preds]\n",
        "            label_list += [data.item() for data in y]\n",
        "\n",
        "    loss_sum /= num_batches\n",
        "    correct /= size / 100\n",
        "    print(f\"{state.ljust(5)}  Accuracy: {(correct):>5.1f}%, AvgLoss: {loss_sum:>7f}\")\n",
        "    return loss_sum, pred_list, label_list\n",
        "\n",
        "\n",
        "def plot_cm(label: list, pred: list, state: str, save: bool, subject: str):\n",
        "    \"\"\"Plots confusion matrix\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    label : list\n",
        "        List of true label\n",
        "    pred : list\n",
        "        List of predicted label\n",
        "    state : string\n",
        "        State either\"Train\" or \"Val\"\n",
        "    save : bool\n",
        "        Option to save the figure\n",
        "    subject : string\n",
        "        Name of the subject\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(label, pred)\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt=\"d\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=[\"jump\", \"dash\", \"stay\"],\n",
        "        yticklabels=[\"jump\", \"dash\", \"stay\"],\n",
        "    )\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(f\"{state} Confusion Matrix\")\n",
        "    if save:\n",
        "        plt.savefig(f\"./output/{subject}_{state}_cf.png\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # exp parameters\n",
        "    infer_sec = 4\n",
        "    rec_sec = 8\n",
        "    batch_size = 5\n",
        "    num_epoch = 15\n",
        "    channel_num = 3  # left, right, diff\n",
        "    label_num = 3  # jump, dash, stay\n",
        "    sample_freq = 1800\n",
        "\n",
        "    # loading eeg\n",
        "    subject = input(\"Subject Name: \")\n",
        "    eeg = load_eeg(subject)\n",
        "    print(f\"EEG-data length : {len(eeg)}\")\n",
        "    col_names = [\"left\", \"right\", \"diff\"]\n",
        "    plot_eeg(eeg, col_names)\n",
        "\n",
        "    # preprocess\n",
        "    eeg = preprocess(eeg, col_names, sample_freq, rec_sec)\n",
        "    plot_eeg(eeg, col_names)\n",
        "\n",
        "    # constructing dataloader\n",
        "    df_train, df_test, infer_len = split_data(eeg, infer_sec, rec_sec)\n",
        "    train_dataset = EEGDataset(df_train)\n",
        "    test_dataset = EEGDataset(df_test)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # model construction\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using {device} device\")\n",
        "    args = sys.argv\n",
        "    if len(args) == 2 and args[1].lower() != \"eegnet\":\n",
        "        if args[1].lower() == \"conformer\":\n",
        "            print(\"Using Conformer\")\n",
        "            model = Conformer(infer_len=infer_len, label=label_num, ch=channel_num)\n",
        "    else:\n",
        "        print(\"Using EEGNet\")\n",
        "        model = EEGNet(\n",
        "            infer_len=infer_len, sample_freq=sample_freq, C=channel_num, N=label_num\n",
        "        )\n",
        "\n",
        "    model.to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
        "\n",
        "    # model training\n",
        "    train_loss_hist, test_loss_hist = [], []\n",
        "    for t in range(num_epoch):\n",
        "        string = \"-\" * 30\n",
        "        print(f\"Epoch {t+1}\\n{string}\")\n",
        "        train_loss, train_pred, train_label = train(\n",
        "            train_dataloader, model, loss_fn, optimizer, device, state=\"Train\"\n",
        "        )\n",
        "        test_loss, test_pred, test_label = train(\n",
        "            test_dataloader, model, loss_fn, optimizer, device, state=\"Val\"\n",
        "        )\n",
        "        train_loss_hist.append(train_loss)\n",
        "        test_loss_hist.append(test_loss)\n",
        "        print()\n",
        "    torch.save(model, f\"./models/{subject}_model_weight.pth\")\n",
        "\n",
        "    plt.plot(train_loss_hist, label=\"train_loss\")\n",
        "    plt.plot(test_loss_hist, label=\"test_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plot_cm(train_label, train_pred, state=\"Train\", save=True, subject=subject)\n",
        "    plot_cm(test_label, test_pred, state=\"Val\", save=True, subject=subject)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.getLogger(\"matplotlib.font_manager\").disabled = True\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7r_aO8Gu_d",
        "outputId": "e78593c5-bb8d-457c-b082-a2e04bb30207"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting models\n",
            "  Using cached models-0.9.3.tar.gz (16 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg0e0T-3GAvr",
        "outputId": "c0adc185-9d43-44a9-aacc-75698962191e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting models\n",
            "  Using cached models-0.9.3.tar.gz (16 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "TWqvNIPWH-Kf",
        "outputId": "34673d1c-5624-44fe-8463-1eda9a055e7a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-180ce836a0cb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    install models\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRacNTSLGBEt",
        "outputId": "a8857061-676a-40d3-e67f-a221a4194a19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0S2O4YRFGBIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}